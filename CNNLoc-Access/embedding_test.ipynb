{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:22:02.492206600Z",
     "start_time": "2024-04-17T06:22:00.572398786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA_VISIBLE_DEVICES\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtensorflow_backend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_session\n\u001B[0;32m---> 17\u001B[0m config\u001B[38;5;241m=\u001B[39m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConfigProto\u001B[49m()\n\u001B[1;32m     18\u001B[0m config\u001B[38;5;241m.\u001B[39mgpu_options\u001B[38;5;241m.\u001B[39mper_process_gpu_memory_fraction\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m\n\u001B[1;32m     19\u001B[0m set_session(tf\u001B[38;5;241m.\u001B[39mSession(config\u001B[38;5;241m=\u001B[39mconfig))\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "from encoder_model import EncoderDNN\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import data_helper_413 as DataHelper\n",
    "import model_413 as Model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.9\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test_csv_path=os.path.join(base_dir,'/home/aries/413/CNNLoc-Access/TestData.csv')\n",
    "# valid_csv_path=os.path.join(base_dir,'/home/aries/413/BSSID_CNNLOC/CNNLoc-Access/ValidationData.csv')\n",
    "# train_csv_path=os.path.join(base_dir,'/home/aries/413/BSSID_CNNLOC/CNNLoc-Access/TrainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.488372160Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.normalize_valid_x= None\n",
    "        self.normalize_x= None\n",
    "        self.normalize_y= None\n",
    "        self.normalize_valid_y= None\n",
    "\n",
    "    def _preprocess(self, x, y, valid_x, valid_y, data_helper):\n",
    "        #self.normY = data_helper_413.NormY()\n",
    "        self.normalize_x = data_helper.normalizeX(x)\n",
    "        self.normalize_valid_x = data_helper.normalizeX(valid_x)\n",
    "\n",
    "        data_helper.normY.fit(y[:, 0], y[:, 1])\n",
    "        self.longitude_normalize_y, self.latitude_normalize_y = data_helper.normY.normalizeY(y[:, 0], y[:, 1])\n",
    "        self.floorID_y = y[:, 2]\n",
    "        self.buildingID_y = y[:, 3]\n",
    "\n",
    "        self.longitude_normalize_valid_y, self.latitude_normalize_valid_y = data_helper.normY.normalizeY(valid_y[:, 0],valid_y[:, 1])\n",
    "        self.floorID_valid_y = valid_y[:, 2]\n",
    "        self.buildingID_valid_y = valid_y[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.488968610Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir= os.getcwd()\n",
    "test_csv_path=os.path.join(base_dir,'/home/aries/413/BSSID_CNNLOC/CNNLoc-Access/UTSIndoorLoc/UTS_test.csv')\n",
    "valid_csv_path=os.path.join(base_dir,'/home/aries/413/BSSID_CNNLOC/CNNLoc-Access/UTSIndoorLoc/UTS_test.csv')\n",
    "train_csv_path=os.path.join(base_dir,'/home/aries/413/BSSID_CNNLOC/CNNLoc-Access/UTSIndoorLoc/UTS_training.csv')\n",
    "\n",
    "data_helper = DataHelper.DataHelper()\n",
    "data_helper.set_config(wap_size=589,long=589,lat=590,floor=591,building_id=592) # UTSIndoorLoc\n",
    "# data_helper.set_config(wap_size=301,long=301,lat=302,floor=303,building_id=304) # Self-collected\n",
    "# data_helper.set_config(wap_size=520,long=520,lat=521,floor=522,building_id=523) # UJIIndoorLoc\n",
    "(train_x, train_y), (valid_x, valid_y),(test_x,test_y) = data_helper.load_data_all(train_csv_path, valid_csv_path,test_csv_path)\n",
    "\n",
    "# (train_x,train_y) = Model.filter_building(train_x,train_y,1)\n",
    "# (valid_x, valid_y) = Model.filter_building(valid_x, valid_y,1)\n",
    "nn_model = NN()\n",
    "nn_model._preprocess(train_x,train_y,valid_x,valid_y,data_helper)\n",
    "\n",
    "wap_size = train_x.shape[1]\n",
    "print(\"Number of WAPs: \" + str(wap_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We preprocess the data, first by normalizing it, then we split it into a signal strength matrix and rank matrix, which is the input into the embedding. The rank matrix takes the indices of the WAPs and sorts them via the magnitude of the signal strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.489402103Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, match_length=0):\n",
    "    # Initialize lists to store the preprocessed indices and signal strengths\n",
    "    preprocessed_indices = []\n",
    "    preprocessed_strengths = []\n",
    "\n",
    "    # Iterate over each sample in the batch\n",
    "    for sample in data:\n",
    "        # Find the indices and values of non-zero signal strengths\n",
    "        non_zero_indices = np.nonzero(sample)[0]\n",
    "        non_zero_values = sample[non_zero_indices]\n",
    "\n",
    "        # Sort the indices by signal strength in descending order\n",
    "        sorted_indices = non_zero_indices[np.argsort(-non_zero_values)]\n",
    "        sorted_values = non_zero_values[np.argsort(-non_zero_values)]\n",
    "\n",
    "        # Append the sorted indices and values to the preprocessed data\n",
    "        preprocessed_indices.append(sorted_indices)\n",
    "        preprocessed_strengths.append(sorted_values)\n",
    "\n",
    "    # Determine the maximum number of non-zero values in a sample\n",
    "    M = max(len(indices) for indices in preprocessed_indices)\n",
    "    \n",
    "    if match_length > 0:\n",
    "        M = match_length\n",
    "\n",
    "    # Pad each list of indices and signal strengths to have the same length\n",
    "    for i in range(len(preprocessed_indices)):\n",
    "        padding = M - len(preprocessed_indices[i])\n",
    "        preprocessed_indices[i] = np.pad(preprocessed_indices[i], (0, padding), 'constant')\n",
    "        preprocessed_strengths[i] = np.pad(preprocessed_strengths[i], (0, padding), 'constant')\n",
    "\n",
    "    # Stack the preprocessed data to form the final output\n",
    "    preprocessed_indices = np.stack(preprocessed_indices)\n",
    "    preprocessed_strengths = np.stack(preprocessed_strengths)\n",
    "\n",
    "    return preprocessed_indices, preprocessed_strengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "This model uses an embedding layer as the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.489721143Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.init import kaiming_uniform_, xavier_uniform_, xavier_normal_\n",
    "\n",
    "class LocalizationModel(nn.Module):\n",
    "    def __init__(self, num_waps, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LocalizationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_waps, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        xavier_normal_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x, signal_strengths):\n",
    "        # x is of shape (batch_size, M), where M is the maximum number of non-zero signal strengths in a sample\n",
    "        # signal_strengths is of shape (batch_size, M), corresponding to the signal strengths of the WAPs in x\n",
    "\n",
    "        # Embed the WAP indices\n",
    "        x = self.embedding(x)  # shape: (batch_size, M, embedding_dim)\n",
    "\n",
    "        # Multiply the embeddings by the signal strengths\n",
    "        x = x * signal_strengths.unsqueeze(-1)  # shape: (batch_size, M, embedding_dim)\n",
    "\n",
    "        # Sum across the signal strength dimension to get a single vector for each sample\n",
    "        x = x.sum(dim=1)  # shape: (batch_size, embedding_dim)\n",
    "\n",
    "        # Pass through the first fully connected layer\n",
    "        x = self.fc1(x)  # shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Apply a ReLU activation function\n",
    "        x = nn.ReLU()(x)\n",
    "\n",
    "        # Pass through the second fully connected layer to get the output\n",
    "        out = self.fc2(x)  # shape: (batch_size, output_dim)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "First we build the DataLoaders from the seperated input data as well as the target values. Then we run the training algorithm for the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.490142029Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Preprocess the data\n",
    "pre_x, pre_strengths = preprocess_data(nn_model.normalize_x)\n",
    "pre_valid_x, pre_valid_strengths = preprocess_data(nn_model.normalize_valid_x, match_length=pre_x.shape[1])\n",
    "pre_y = nn_model.floorID_y\n",
    "pre_valid_y = nn_model.floorID_valid_y\n",
    "\n",
    "# Convert the preprocessed data to PyTorch tensors\n",
    "pre_y = np.vstack(pre_y).astype(np.long)\n",
    "pre_valid_y = np.vstack(pre_valid_y).astype(np.long)\n",
    "\n",
    "# Offset floors to account for basements\n",
    "offset = pre_y.min() \n",
    "pre_y -= offset\n",
    "pre_valid_y -= offset\n",
    "num_classes = pre_y.max() + 1\n",
    "\n",
    "# Convert the datasets to PyTorch tensors\n",
    "pre_x = torch.tensor(pre_x, dtype=torch.long)\n",
    "pre_strengths = torch.tensor(pre_strengths, dtype=torch.float32)\n",
    "pre_valid_x = torch.tensor(pre_valid_x, dtype=torch.long)\n",
    "pre_valid_strengths = torch.tensor(pre_valid_strengths, dtype=torch.float32)\n",
    "# pre_y = torch.tensor(pre_y, dtype=torch.long)\n",
    "# pre_valid_y = torch.tensor(pre_valid_y, dtype=torch.long)\n",
    "pre_y = torch.tensor(pre_y.T[0], dtype=torch.long)\n",
    "pre_valid_y = torch.tensor(pre_valid_y.T[0], dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(pre_x, pre_strengths, pre_y)\n",
    "valid_dataset = TensorDataset(pre_valid_x, pre_valid_strengths, pre_valid_y)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "print(pre_x.shape, pre_strengths.shape, pre_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.490937133Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LocalizationModel(520, 50, 50, 5)\n",
    "\n",
    "x = pre_x\n",
    "signal_strengths = pre_strengths\n",
    "\n",
    "# print(model.embedding.weight.data)\n",
    "\n",
    "x = model.embedding(x)  # shape: (batch_size, M, embedding_dim)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# Multiply the embeddings by the signal strengths\n",
    "x = x * signal_strengths.unsqueeze(-1)  # shape: (batch_size, M, embedding_dim)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# Sum across the signal strength dimension to get a single vector for each sample\n",
    "x = x.sum(dim=1)  # shape: (batch_size, embedding_dim)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# Pass through the first fully connected layer\n",
    "x = model.fc1(x)  # shape: (batch_size, hidden_dim)\n",
    "\n",
    "# print(x.shape)\n",
    "\n",
    "# Apply a ReLU activation function\n",
    "x = nn.ReLU()(x)\n",
    "\n",
    "# print(x[1])\n",
    "\n",
    "# Pass through the second fully connected layer to get the output\n",
    "out = model.fc2(x)  # shape: (batch_size, output_dim)\n",
    "\n",
    "# print(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.491228662Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print(torch.cuda.get_arch_list())\n",
    "\n",
    "\n",
    "def train_emb_model(model, num_epochs, learning_rate):\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize lists to store losses and accuracies\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        train_loss, train_correct, total = 0, 0, 0\n",
    "        model.train()\n",
    "        for i, (inputs, signal_strengths, targets) in enumerate(train_loader):\n",
    "            inputs, signal_strengths, targets = inputs.to(device), signal_strengths.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, signal_strengths)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accs.append(train_correct / total)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_correct, total = 0, 0, 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, signal_strengths, targets) in enumerate(val_loader):\n",
    "                inputs, signal_strengths, targets = inputs.to(device), signal_strengths.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs, signal_strengths)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accs.append(val_correct / total)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.4f}')\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.491482559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "embedding_dim = 200\n",
    "hidden_dim = 200\n",
    "# num_classes = 6\n",
    "\n",
    "model = LocalizationModel(wap_size, embedding_dim, hidden_dim, num_classes).to(device)\n",
    "train_emb_model(model, num_epochs=20, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "We can analyze the cosine similarity by displaying the top 5 WAPs with the highest cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.491824838Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def print_top_five_similar_waps(model):\n",
    "    # Get the embeddings from the model\n",
    "    embeddings = model.embedding.weight.data\n",
    "\n",
    "    # Iterate over each WAP\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        # Compute the cosine similarity with all other WAPs\n",
    "        similarities = cosine_similarity(embeddings[i].unsqueeze(0), embeddings)\n",
    "\n",
    "        # Get the indices of the top five most similar WAPs\n",
    "        top_five_indices = similarities.topk(6)[1]\n",
    "\n",
    "        # Remove the WAP itself from the list\n",
    "        top_five_indices = top_five_indices[top_five_indices != i]\n",
    "\n",
    "        # Print the WAP and its top five most similar WAPs\n",
    "        print(f'WAP {i+1}:', ', '.join(f'WAP {j+1} (similarity: {similarities[j]:.4f})' for j in top_five_indices))\n",
    "\n",
    "print_top_five_similar_waps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.492078415Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_embeddings(model):\n",
    "    # Get the embeddings from the model\n",
    "    embeddings = model.embedding.weight.data.cpu().numpy()\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Plot the embeddings\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "    for i, coords in enumerate(embeddings_2d):\n",
    "        plt.text(coords[0], coords[1], str(i+1), verticalalignment='bottom', horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "visualize_embeddings(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected\n",
    "We train another fully connected model for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T06:22:02.496866311Z",
     "start_time": "2024-04-17T06:22:02.492414175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "class FullyConnectedModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        out = self.fc3(x)\n",
    "        return out\n",
    "    \n",
    "# Reshape the data\n",
    "pre_x = nn_model.normalize_x\n",
    "pre_valid_x = nn_model.normalize_valid_x\n",
    "\n",
    "# Convert the datasets to PyTorch tensors\n",
    "pre_x_flat = torch.tensor(pre_x, dtype=torch.float32)\n",
    "pre_valid_x_flat = torch.tensor(pre_valid_x, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset_flat = TensorDataset(pre_x_flat, pre_y)\n",
    "valid_dataset_flat = TensorDataset(pre_valid_x_flat, pre_valid_y)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader_flat = DataLoader(train_dataset_flat, batch_size=batch_size, shuffle=True)\n",
    "val_loader_flat = DataLoader(valid_dataset_flat, batch_size=batch_size)\n",
    "\n",
    "def train_model(model, num_epochs, learning_rate):\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize lists to store losses and accuracies\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        train_loss, train_correct, total = 0, 0, 0\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(train_loader_flat):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader_flat))\n",
    "        train_accs.append(train_correct / total)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_correct, total = 0, 0, 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets) in enumerate(val_loader_flat):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader_flat))\n",
    "        val_accs.append(val_correct / total)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.4f}')\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "model = FullyConnectedModel(wap_size, hidden_dim, num_classes).to(device)\n",
    "train_model(model, num_epochs=20, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.492590387Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_bow_waps(data, strengths, target, window_size=3):\n",
    "    res = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        if data[i+window_size-1] == 0:\n",
    "            break\n",
    "        res.append([data[i:i+window_size], strengths[i:i+window_size], target])\n",
    "    return res\n",
    "\n",
    "# Preprocess the data\n",
    "pre_x, pre_strengths = preprocess_data(nn_model.normalize_x)\n",
    "pre_valid_x, pre_valid_strengths = preprocess_data(nn_model.normalize_valid_x)\n",
    "pre_y = nn_model.floorID_y\n",
    "pre_valid_y = nn_model.floorID_valid_y\n",
    "\n",
    "# Convert the data to bag of WAPs format\n",
    "bow_waps_data = [to_bow_waps(x, s, y) for x, s, y in zip(pre_x, pre_strengths, pre_y)]\n",
    "\n",
    "# Flatten the data\n",
    "bow_waps_data = [item for sublist in bow_waps_data for item in sublist]\n",
    "\n",
    "# Separate the WAP indices, signal strengths, and targets\n",
    "bow_waps_indices = [item[0] for item in bow_waps_data]\n",
    "bow_waps_strengths = [item[1] for item in bow_waps_data]\n",
    "bow_waps_targets = [item[2] for item in bow_waps_data]\n",
    "\n",
    "# Convert the datasets to PyTorch tensors\n",
    "bow_waps_indices = torch.tensor(bow_waps_indices, dtype=torch.long)\n",
    "bow_waps_strengths = torch.tensor(bow_waps_strengths, dtype=torch.float32)\n",
    "bow_waps_targets = torch.tensor(bow_waps_targets, dtype=torch.long)\n",
    "pre_valid_x = torch.tensor(pre_valid_x, dtype=torch.long)\n",
    "pre_valid_strengths = torch.tensor(pre_valid_strengths, dtype=torch.float32)\n",
    "pre_valid_y = torch.tensor(pre_valid_y, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(bow_waps_indices, bow_waps_strengths, bow_waps_targets)\n",
    "valid_dataset = TensorDataset(pre_valid_x, pre_valid_strengths, pre_valid_y)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.492786670Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "hidden_dim = 200\n",
    "\n",
    "model = LocalizationModel(wap_size, embedding_dim, hidden_dim, num_classes).to(device)\n",
    "train_emb_model(model, num_epochs=10, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.492955060Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_waps, embedding_dim, hidden_dim, output_dim):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_waps, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        kaiming_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x, signal_strengths):\n",
    "        # x is of shape (batch_size, M), where M is the maximum number of non-zero signal strengths in a sample\n",
    "        # signal_strengths is of shape (batch_size, M), corresponding to the signal strengths of the WAPs in x\n",
    "\n",
    "        # Embed the WAP indices\n",
    "        x = self.embedding(x)  # shape: (batch_size, M, embedding_dim)\n",
    "\n",
    "        # Multiply the embeddings by the signal strengths\n",
    "        x = x * signal_strengths.unsqueeze(-1)  # shape: (batch_size, M, embedding_dim)\n",
    "\n",
    "        # Transpose the tensor to match the input shape requirement of nn.Conv1d\n",
    "        x = x.transpose(1, 2)  # shape: (batch_size, embedding_dim, M)\n",
    "\n",
    "        # Pass through the first convolutional layer\n",
    "        x = self.conv1(x)  # shape: (batch_size, hidden_dim, M)\n",
    "\n",
    "        # Apply a ReLU activation function\n",
    "        x = nn.ReLU()(x)\n",
    "\n",
    "        # Pass through the second convolutional layer\n",
    "        x = self.conv2(x)  # shape: (batch_size, hidden_dim, M)\n",
    "\n",
    "        # Apply a ReLU activation function\n",
    "        x = nn.ReLU()(x)\n",
    "\n",
    "        # Sum across the signal strength dimension to get a single vector for each sample\n",
    "        x = x.sum(dim=2)  # shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Pass through the fully connected layer to get the output\n",
    "        out = self.fc(x)  # shape: (batch_size, output_dim)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.507736911Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "hidden_dim = 200\n",
    "\n",
    "model = CNNModel(wap_size, embedding_dim, hidden_dim, num_classes).to(device)\n",
    "train_emb_model(model, num_epochs=20, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.507985172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "class FullyConnectedModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        out = self.fc3(x)\n",
    "        return out\n",
    "    \n",
    "# Reshape the data\n",
    "pre_x = nn_model.normalize_x\n",
    "pre_valid_x = nn_model.normalize_valid_x\n",
    "\n",
    "# Convert the datasets to PyTorch tensors\n",
    "pre_x_flat = torch.tensor(pre_x, dtype=torch.float32)\n",
    "pre_valid_x_flat = torch.tensor(pre_valid_x, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset_flat = TensorDataset(pre_x_flat, pre_y)\n",
    "valid_dataset_flat = TensorDataset(pre_valid_x_flat, pre_valid_y)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader_flat = DataLoader(train_dataset_flat, batch_size=batch_size, shuffle=True)\n",
    "val_loader_flat = DataLoader(valid_dataset_flat, batch_size=batch_size)\n",
    "\n",
    "def train_model(model, num_epochs, learning_rate):\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize lists to store losses and accuracies\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        train_loss, train_correct, total = 0, 0, 0\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(train_loader_flat):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader_flat))\n",
    "        train_accs.append(train_correct / total)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_correct, total = 0, 0, 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets) in enumerate(val_loader_flat):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader_flat))\n",
    "        val_accs.append(val_correct / total)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.4f}')\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "model = FullyConnectedModel(wap_size, hidden_dim, num_classes).to(device)\n",
    "train_model(model, num_epochs=20, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.508166527Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T06:22:02.508330815Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(num_waps, embedding_dim, hidden_dim, output_dim):\n",
    "    # Parameters in the embedding layer\n",
    "    embedding_params = num_waps * embedding_dim\n",
    "\n",
    "    # Parameters in the first convolutional layer\n",
    "    conv1_params = embedding_dim * hidden_dim\n",
    "\n",
    "    # Parameters in the second convolutional layer\n",
    "    conv2_params = hidden_dim * hidden_dim\n",
    "\n",
    "    # Parameters in the fully connected layer\n",
    "    fc_params = hidden_dim * output_dim\n",
    "\n",
    "    # Total number of parameters\n",
    "    total_params = embedding_params + conv1_params + conv2_params + fc_params\n",
    "\n",
    "    return total_params\n",
    "\n",
    "print(count_parameters(520, 200, 200, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
